{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3VXu4zfNDHi",
        "outputId": "c68b5d76-237e-4b97-dcb6-5de7cc91f98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/divyanshrai/handwritten-signatures?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 370M/370M [00:02<00:00, 169MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 815ms/step - accuracy: 0.8396 - loss: 0.5377 - val_accuracy: 0.9563 - val_loss: 0.4422\n",
            "Epoch 2/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.9612 - loss: 0.4076 - val_accuracy: 0.9750 - val_loss: 0.3799\n",
            "Epoch 3/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 887ms/step - accuracy: 0.9476 - loss: 0.4044 - val_accuracy: 0.9438 - val_loss: 0.3785\n",
            "Epoch 4/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 738ms/step - accuracy: 0.9468 - loss: 0.4036 - val_accuracy: 0.9250 - val_loss: 0.4463\n",
            "Epoch 5/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 736ms/step - accuracy: 0.9638 - loss: 0.3683 - val_accuracy: 0.9563 - val_loss: 0.3555\n",
            "Epoch 6/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 884ms/step - accuracy: 0.9508 - loss: 0.3711 - val_accuracy: 0.9563 - val_loss: 0.3516\n",
            "Epoch 7/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 807ms/step - accuracy: 0.9618 - loss: 0.3192 - val_accuracy: 0.9625 - val_loss: 0.3573\n",
            "Epoch 8/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 781ms/step - accuracy: 0.9724 - loss: 0.3176 - val_accuracy: 0.9438 - val_loss: 0.3441\n",
            "Epoch 9/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 824ms/step - accuracy: 0.9466 - loss: 0.3455 - val_accuracy: 0.9500 - val_loss: 0.3064\n",
            "Epoch 10/10\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 706ms/step - accuracy: 0.9726 - loss: 0.3181 - val_accuracy: 0.9875 - val_loss: 0.2784\n",
            "Final Training Accuracy: 96.75%\n",
            "Final Validation Accuracy: 98.75%\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install --quiet tensorflow matplotlib pillow opencv-python kagglehub\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import kagglehub\n",
        "\n",
        "# Download the latest dataset version from Kaggle\n",
        "dataset_dir = kagglehub.dataset_download(\"divyanshrai/handwritten-signatures\")\n",
        "\n",
        "# Function to collect all images from the dataset\n",
        "def collect_images(base_dir):\n",
        "    exts = ['*.png', '*.jpg', '*.jpeg']\n",
        "    images = []\n",
        "    for ext in exts:\n",
        "        images.extend(glob(os.path.join(base_dir, '**', ext), recursive=True)) #search all subfolders.\n",
        "    return images\n",
        "\n",
        "all_imgs = collect_images(dataset_dir)\n",
        "\n",
        "# Build a dictionary mapping writers to their images\n",
        "writers_dict = {}\n",
        "for img_path in all_imgs:\n",
        "    filename = os.path.basename(img_path)\n",
        "    writer_id = filename.split(\"_\")[0]\n",
        "    writers_dict.setdefault(writer_id, []).append(img_path)\n",
        "\n",
        "writers = list(writers_dict.keys())\n",
        "\n",
        "# Function to load and preprocess images\n",
        "IMG_SIZE = (100, 100)\n",
        "def load_img(path):\n",
        "    img = Image.open(path).convert('L').resize(IMG_SIZE)\n",
        "    arr = np.array(img) / 255.0\n",
        "    return np.expand_dims(arr, axis=-1)\n",
        "\n",
        "# Generator for image pairs (same writer or different writers)\n",
        "def pair_generator(batch_size=32):\n",
        "    while True:\n",
        "        X1, X2, y = [], [], []\n",
        "        for _ in range(batch_size):\n",
        "            if random.random() < 0.5:\n",
        "                w = random.choice(writers)\n",
        "                if len(writers_dict[w]) < 2:\n",
        "                    continue\n",
        "                imgs = random.sample(writers_dict[w], 2)\n",
        "                label = 1\n",
        "            else:\n",
        "                if len(writers) < 2:\n",
        "                    continue\n",
        "                w1, w2 = random.sample(writers, 2)\n",
        "                imgs = [random.choice(writers_dict[w1]), random.choice(writers_dict[w2])]\n",
        "                label = 0\n",
        "            X1.append(load_img(imgs[0]))\n",
        "            X2.append(load_img(imgs[1]))\n",
        "            y.append(label)\n",
        "        yield (np.array(X1, dtype=np.float32), np.array(X2, dtype=np.float32)), np.array(y, dtype=np.float32)\n",
        "\n",
        "# Create TensorFlow dataset from the generator\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: pair_generator(BATCH_SIZE),\n",
        "    output_signature=(\n",
        "        (tf.TensorSpec(shape=(None, 100, 100, 1), dtype=tf.float32),\n",
        "         tf.TensorSpec(shape=(None, 100, 100, 1), dtype=tf.float32)),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Build the base CNN for Siamese network\n",
        "def build_base(input_shape=(100,100,1)):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Construct Siamese network\n",
        "base_net = build_base()\n",
        "input_a = layers.Input(shape=(100,100,1))\n",
        "input_b = layers.Input(shape=(100,100,1))\n",
        "feat_a = base_net(input_a)\n",
        "feat_b = base_net(input_b)\n",
        "distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([feat_a, feat_b])\n",
        "output = layers.Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = models.Model([input_a, input_b], output)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "STEPS = 50\n",
        "VAL_STEPS = 10\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=STEPS,\n",
        "    validation_data=train_dataset,\n",
        "    validation_steps=VAL_STEPS,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Print final training and validation accuracy\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"Final Training Accuracy: {final_train_acc*100:.2f}%\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"siamese_model.keras\")\n"
      ],
      "metadata": {
        "id": "CvK7Oyky553j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"siamese_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z8rT0KZX5882",
        "outputId": "48def949-5f6e-4c6c-d484-868157b15cfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2a36825c-dc22-4226-8ea7-7d6590e1e411\", \"siamese_model.keras\", 52279499)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bjI9FvlDJZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}